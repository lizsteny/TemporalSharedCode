{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ca70d27-13db-42e9-acc4-9a591d522b6a",
      "metadata": {
        "collapsed": true,
        "jp-MarkdownHeadingCollapsed": true,
        "jupyter": {
          "is_executing": true,
          "outputs_hidden": true
        },
        "id": "7ca70d27-13db-42e9-acc4-9a591d522b6a"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab7838e-c57c-4ba1-b593-a3044b7b3cab",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-12-12T09:52:32.103367Z",
          "start_time": "2024-12-12T09:52:31.115739Z"
        },
        "id": "eab7838e-c57c-4ba1-b593-a3044b7b3cab"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbeaf59e-9b5a-407b-ad92-c1080a5c5115",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "dbeaf59e-9b5a-407b-ad92-c1080a5c5115"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pre-processing"
      ],
      "metadata": {
        "id": "lVzAVX0pu6n1"
      },
      "id": "lVzAVX0pu6n1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564c9906-8094-4636-a86f-18910ecd1432",
      "metadata": {
        "id": "564c9906-8094-4636-a86f-18910ecd1432"
      },
      "outputs": [],
      "source": [
        "def parse_tblout(file_path, e_value_threshold=None):\n",
        "    \"\"\"\n",
        "    Parse a .tblout file and create a DataFrame with optional E-value filtering\n",
        "    \"\"\"\n",
        "    # Define column names\n",
        "    columns = [\n",
        "        \"target_name\", \"accession\", \"tlen\", \"query_name\", \"query_accession\", \"qlen\",\n",
        "        \"E-value\", \"score\", \"bias\", \"#\", \"of\", \"c-Evalue\", \"i-Evalue\",\n",
        "        \"domain_score\", \"domain_bias\", \"hmm_from\", \"hmm_to\", \"ali_from\", \"ali_to\",\n",
        "        \"env_from\", \"env_to\", \"acc\", \"description_of_target\"\n",
        "    ]\n",
        "\n",
        "    # read the file\n",
        "    with open(file_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # extract data lines (skip header and dashed lines)\n",
        "    data_lines = lines[3:]  # skip the header and separator lines\n",
        "    data_lines = [line.strip() for line in data_lines if not line.startswith(\"#\")]\n",
        "\n",
        "    # parse the data into rows\n",
        "    rows = [line.split() for line in data_lines]\n",
        "    data_table = pd.DataFrame(rows, columns=columns)\n",
        "\n",
        "    # convert numeric columns to proper types\n",
        "    numeric_cols = [\"E-value\", \"c-Evalue\", \"i-Evalue\", \"score\", \"domain_score\"]\n",
        "    data_table[numeric_cols] = data_table[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "    # apply E-value filtering if threshold is provided\n",
        "    if e_value_threshold is not None:\n",
        "        data_table = data_table[data_table[\"E-value\"] <= e_value_threshold]\n",
        "\n",
        "    return data_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "372fb5e9-0d05-4dde-b61b-b807260a9e37",
      "metadata": {
        "id": "372fb5e9-0d05-4dde-b61b-b807260a9e37"
      },
      "outputs": [],
      "source": [
        "def create_binary_matrix(data_table, sequence_count):\n",
        "    \"\"\"\n",
        "    Create a binary matrix with sequences as rows and targets as columns.\n",
        "\n",
        "    Parameters:\n",
        "    data_table: pd.DataFrame\n",
        "        Table with \"query_name\" and \"target_name\" columns.\n",
        "    sequence_count: int\n",
        "        Total number of sequences (seq1 to seqN).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame\n",
        "        Binary matrix with 1 for presence and 0 for absence of targets.\n",
        "    \"\"\"\n",
        "    # create a binary matrix using crosstab\n",
        "    binary_matrix = pd.crosstab(data_table[\"query_name\"], data_table[\"target_name\"])\n",
        "\n",
        "    # ensure the values are binary (1/0)\n",
        "    binary_matrix = binary_matrix.astype(bool).astype(int)\n",
        "\n",
        "    # remove the names for rows and columns\n",
        "    binary_matrix.index.name = None\n",
        "    binary_matrix.columns.name = None\n",
        "\n",
        "    # generate the full sequence list (seq1 to seqN)\n",
        "    full_sequence_list = [f\"seq{i}\" for i in range(1, sequence_count + 1)]\n",
        "\n",
        "    # reindex the binary matrix to include all sequences, filling missing rows with zeros\n",
        "    binary_matrix = binary_matrix.reindex(full_sequence_list, fill_value=0)\n",
        "    binary_matrix.index.name = \"sequence\"\n",
        "\n",
        "    # remove columns where all values are 0\n",
        "    binary_matrix = binary_matrix.loc[:, binary_matrix.any(axis=0)]\n",
        "\n",
        "    return binary_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model exploration"
      ],
      "metadata": {
        "id": "QzWXmSYLvc1-"
      },
      "id": "QzWXmSYLvc1-"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(descriptor):\n",
        "    \"\"\"\n",
        "    Loads feature data from a CSV file, sets the sequence ID as the index,\n",
        "    and filters out features with zero variance.\n",
        "\n",
        "    Parameters:\n",
        "    descriptor: str\n",
        "        The name of the feature descriptor, used to locate the CSV file.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame\n",
        "        A df with sequences as rows and filtered features as columns.\n",
        "    \"\"\"\n",
        "    file_path = os.path.join(input_path, f\"{descriptor}.csv\")\n",
        "    x = pd.read_csv(file_path)\n",
        "    x.set_index(x.columns[0], inplace=True)\n",
        "    x.rename_axis(\"sequence\", inplace=True)\n",
        "    return x.loc[:, (x != 0).any(axis=0)]"
      ],
      "metadata": {
        "id": "Fs-BHzVWv8DD"
      },
      "id": "Fs-BHzVWv8DD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_top_features(x, descriptor, top_n=10):\n",
        "    \"\"\"\n",
        "    Plot and save histograms of the top features.\n",
        "\n",
        "    Parameters:\n",
        "    Descriptor: str\n",
        "        name of the feature descriptor used for labeling the plot and saving the file.\n",
        "    top_n: int, optional\n",
        "        The number of top features to plot (default is 10).\n",
        "    x: pd.DataFrame\n",
        "        Feature data where rows are sequences and columns are features.\n",
        "\n",
        "    Saves:\n",
        "    A histogram plot of the top features in the `results_dir` folder.\n",
        "    \"\"\"\n",
        "    # determine the actual number of features to plot\n",
        "    available_features = min(top_n, x.shape[1])  # use top_n or total number of columns, whichever is smaller\n",
        "    top_features = x.mean(axis=0).nlargest(available_features).index\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for feature in top_features:\n",
        "        plt.hist(x[feature], bins=30, alpha=0.5, label=feature)\n",
        "\n",
        "    plt.title(f\"Top {available_features} Features Distribution for {descriptor}\")\n",
        "    plt.xlabel(\"Feature values\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.savefig(os.path.join(results_dir, f\"{descriptor}_top_features_distribution.png\"))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "BO3ZaMYXv_C5"
      },
      "id": "BO3ZaMYXv_C5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_statistics(x, descriptor):\n",
        "    \"\"\"\n",
        "    Calculate and save descriptive statistics for each feature.\n",
        "    \"\"\"\n",
        "    stats = x.describe()\n",
        "    stats.to_csv(os.path.join(results_dir, f\"{descriptor}_stats.csv\"))"
      ],
      "metadata": {
        "id": "8UCdU2VYwA4s"
      },
      "id": "8UCdU2VYwA4s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_and_plot_correlation(x, y, descriptor):\n",
        "    \"\"\"\n",
        "    Calculate correlations of features with a target variable, save the results,\n",
        "    and plot the sorted correlations.\n",
        "\n",
        "    Parameters:\n",
        "    x: pd.DataFrame\n",
        "        Feature data with rows as samples and columns as features.\n",
        "    y: pd.Series\n",
        "        Target variable (e.g., infection status).\n",
        "    descriptor: str\n",
        "        Descriptor name for labeling and saving the outputs.\n",
        "\n",
        "    Returns:\n",
        "    pd.Series\n",
        "        Sorted correlations of features with the target variable.\n",
        "    \"\"\"\n",
        "    # combine feature data (x) and target variable (y) into a single df\n",
        "    combined_df = pd.concat([x, y], axis=1)\n",
        "\n",
        "    # calculate the correlation matrix\n",
        "    correlation_matrix = combined_df.corr()\n",
        "\n",
        "    # extract correlation with the target variable and remove the target itself\n",
        "    correlation_with_target = correlation_matrix['infection'].drop('infection')\n",
        "\n",
        "    # sort correlations in descending order\n",
        "    sorted_correlations = correlation_with_target.sort_values(ascending=False)\n",
        "\n",
        "    # save the sorted correlations to a CSV file\n",
        "    sorted_correlations.to_csv(os.path.join(results_dir, f\"{descriptor}_correlation.csv\"))\n",
        "\n",
        "    # plot the sorted correlations\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=sorted_correlations.values, y=sorted_correlations.index)\n",
        "    plt.title(f'Correlation of {descriptor} Features with Infection Status')\n",
        "    plt.xlabel('Correlation Coefficient')\n",
        "    plt.ylabel(f'{descriptor} Features')\n",
        "    plt.axvline(0, color='gray', linestyle='--')\n",
        "\n",
        "    # save and close the plot\n",
        "    plt.savefig(os.path.join(results_dir, f\"{descriptor}_correlation_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # return sorted correlations for potential further use\n",
        "    return sorted_correlations"
      ],
      "metadata": {
        "id": "wbTy8mq4wCtl"
      },
      "id": "wbTy8mq4wCtl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_features_by_correlation(x, correlation_with_target, threshold=0):\n",
        "    \"\"\"\n",
        "    Select features based on a correlation threshold if more than 100 features exist.\n",
        "\n",
        "    Parameters:\n",
        "    x: pd.DataFrame\n",
        "        Feature data with rows as samples and columns as features.\n",
        "    correlation_with_target: pd.Series\n",
        "        Correlation values of features with the target variable.\n",
        "    threshold: float, optional\n",
        "        Minimum absolute correlation value to select features (default is 0).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame\n",
        "        Filtered feature data containing only the selected features.\n",
        "    \"\"\"\n",
        "    # add this moment is 0 as is not being use ## double check\n",
        "    # check if the number of descriptors is greater than 100\n",
        "    if len(correlation_with_target) > 100:\n",
        "        # apply threshold if more than 100 descriptors\n",
        "        selected_features = correlation_with_target[correlation_with_target.abs() > threshold].index.tolist()\n",
        "    else:\n",
        "        # select all features if 100 or fewer descriptors are available\n",
        "        selected_features = correlation_with_target.index.tolist()\n",
        "\n",
        "    return x[selected_features]"
      ],
      "metadata": {
        "id": "jMAqkrdawE2V"
      },
      "id": "jMAqkrdawE2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pairplot(x_selected, y_selected, descriptor):\n",
        "    \"\"\"\n",
        "    Create and save a pairplot for the selected features.\n",
        "    \"\"\"\n",
        "    pairplot_data = pd.concat([x_selected, y_selected], axis=1)\n",
        "    pairplot_data.rename(columns={'infection': 'Target'}, inplace=True)\n",
        "    sns.pairplot(pairplot_data, hue='Target', diag_kind='kde', markers=[\"o\", \"s\"])\n",
        "    plt.savefig(os.path.join(results_dir, f\"{descriptor}_pairplot.png\"))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "12gxNZuQwGk0"
      },
      "id": "12gxNZuQwGk0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(x_train, x_test, y_train, y_test, descriptor):\n",
        "    \"\"\"\n",
        "    Train a Random Forest model, evaluate its performance, and save the results.\n",
        "\n",
        "    Parameters:\n",
        "    x_train: pd.DataFrame\n",
        "        Training feature data.\n",
        "    x_test: pd.DataFrame\n",
        "        Test feature data.\n",
        "    y_train: pd.Series or np.array\n",
        "        Training target labels.\n",
        "    y_test: pd.Series or np.array\n",
        "        Test target labels.\n",
        "    descriptor: str\n",
        "        Descriptor name for labeling and saving the output file.\n",
        "\n",
        "    Returns:\n",
        "    RandomForestClassifier\n",
        "        Trained Random Forest model.\n",
        "    \"\"\"\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    # accuracy and classification report\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    with open(os.path.join(results_dir, f\"{descriptor}_evaluation.txt\"), \"w\") as f:\n",
        "        f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
        "        f.write(\"Classification Report:\\n\")\n",
        "        f.write(report)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lJ1MEVNrwLM2"
      },
      "id": "lJ1MEVNrwLM2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate_model(model, x_selected, y_selected, descriptor):\n",
        "    \"\"\"\n",
        "    Perform 10-fold cross-validation on the model and save the results.\n",
        "    \"\"\"\n",
        "    cv_scores = cross_val_score(model, x_selected, y_selected, cv=10)\n",
        "    with open(os.path.join(results_dir, f\"{descriptor}_cv_scores.txt\"), \"w\") as f:\n",
        "        f.write(\"Cross-Validation Scores:\\n\")\n",
        "        f.write(\", \".join(map(str, cv_scores)) + \"\\n\")\n",
        "        f.write(f\"Mean Cross-Validation Score: {cv_scores.mean()}\")"
      ],
      "metadata": {
        "id": "-FdZoRwawUdT"
      },
      "id": "-FdZoRwawUdT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(model, x_selected, descriptor):\n",
        "    \"\"\"\n",
        "    Plot and save feature importance for the trained model.\n",
        "    \"\"\"\n",
        "    importance_df = pd.DataFrame({'Feature': x_selected.columns, 'Importance': model.feature_importances_})\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "    plt.title(f\"Feature Importances for {descriptor}\")\n",
        "    plt.savefig(os.path.join(results_dir, f\"{descriptor}_feature_importance.png\"))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "CH-Xw8XzwVLv"
      },
      "id": "CH-Xw8XzwVLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6eebc4f1-3297-4826-8e02-8658601c7f48",
      "metadata": {
        "id": "6eebc4f1-3297-4826-8e02-8658601c7f48"
      },
      "source": [
        "## Data parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd206445-52a1-4d04-839b-fe76d4a3b780",
      "metadata": {
        "id": "dd206445-52a1-4d04-839b-fe76d4a3b780"
      },
      "outputs": [],
      "source": [
        "# define directory\n",
        "os.chdir(\"/Users/lizsteny/Documents/Academia/MSc Bioinformatics/Project/bif_project\")\n",
        "\n",
        "# parse vog and vfam txt\n",
        "vog_table = parse_tblout(\"data/phmms/vog/vog_matches_domtblout.txt\", e_value_threshold=0.01)\n",
        "vfam_table = parse_tblout(\"data/phmms/vfam/vfam_matches_domtblout.txt\", e_value_threshold=0.01)\n",
        "\n",
        "# create binary matrices\n",
        "vog_binary_matrix = create_binary_matrix(vog_table, sequence_count=3936)\n",
        "vfam_binary_matrix = create_binary_matrix(vfam_table, sequence_count=3936)\n",
        "\n",
        "# concatenate vog and vfam\n",
        "allphmms_binary_matrix = pd.concat([vog_binary_matrix, vfam_binary_matrix], axis=1)\n",
        "\n",
        "# replace NaN values with 0 to ensure binary data\n",
        "allphmms_binary_matrix = allphmms_binary_matrix.fillna(0).astype(int)\n",
        "\n",
        "# save tables to CSV file\n",
        "vog_binary_matrix.to_csv(\"features/pro_features/phmms/vog/vog_table.csv\", index=True)\n",
        "vfam_binary_matrix.to_csv(\"features/pro_features/phmms/vfam/vfam_table.csv\", index=True)\n",
        "allphmms_binary_matrix.to_csv(\"features/pro_features/phmms/allphmms_table.csv\", index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display and print some stats for the PHMMs"
      ],
      "metadata": {
        "id": "db6Iusaq0fxh"
      },
      "id": "db6Iusaq0fxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4d9434-0f8b-4f16-a053-838d3923d212",
      "metadata": {
        "id": "2c4d9434-0f8b-4f16-a053-838d3923d212",
        "outputId": "e820b140-0623-4c50-d03b-a21367340f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VOG table:\n",
            "(560677, 23)\n",
            "  target_name accession  tlen query_name query_accession  qlen        E-value  \\\n",
            "0    VOG23377         -   968       seq1               -  1629  6.900000e-225   \n",
            "1    VOG69164         -  1254       seq1               -  1629   2.900000e-82   \n",
            "2    VOG69164         -  1254       seq1               -  1629   2.900000e-82   \n",
            "3    VOG03312         -   574       seq1               -  1629   9.500000e-76   \n",
            "4    VOG35419         -  1800       seq1               -  1629   3.400000e-58   \n",
            "\n",
            "   score bias  #  ... domain_score  domain_bias  hmm_from  hmm_to ali_from  \\\n",
            "0  751.1  0.0  1  ...        750.7          0.0        56     943       42   \n",
            "1  278.4  0.0  1  ...         36.1          0.1       213     433       60   \n",
            "2  278.4  0.0  2  ...        233.7          0.0       578    1084      362   \n",
            "3  258.0  9.3  1  ...        256.9          9.3        29     470     1170   \n",
            "4  198.5  7.0  1  ...        197.9          7.0      1311    1693     1209   \n",
            "\n",
            "  ali_to env_from env_to   acc description_of_target  \n",
            "0    935        1    966  0.86                     -  \n",
            "1    252       55    347  0.76                     -  \n",
            "2    830      334    866  0.91                     -  \n",
            "3   1614     1144   1627  0.77                     -  \n",
            "4   1597     1196   1621  0.84                     -  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "(131352, 23)\n",
            "  target_name accession  tlen query_name query_accession  qlen        E-value  \\\n",
            "0   VFAM03873         -   976       seq1               -  1629  5.700000e-224   \n",
            "1   VFAM11302         -  1484       seq1               -  1629   9.300000e-66   \n",
            "2   VFAM11302         -  1484       seq1               -  1629   9.300000e-66   \n",
            "3   VFAM11302         -  1484       seq1               -  1629   9.300000e-66   \n",
            "4   VFAM01422         -   609       seq1               -  1629   1.300000e-57   \n",
            "\n",
            "   score  bias  #  ... domain_score  domain_bias  hmm_from  hmm_to ali_from  \\\n",
            "0  747.5   0.0  1  ...        747.0          0.0        56     957       42   \n",
            "1  223.5   7.2  1  ...         18.9          0.0       634     791      473   \n",
            "2  223.5   7.2  2  ...         -3.0          0.0       880     946      714   \n",
            "3  223.5   7.2  3  ...        204.1          4.8      1075    1448     1184   \n",
            "4  197.4  12.0  1  ...         -2.8          2.1       120     159      901   \n",
            "\n",
            "  ali_to env_from env_to   acc description_of_target  \n",
            "0    940        1    966  0.87                     -  \n",
            "1    617      337    631  0.82                     -  \n",
            "2    780      710    789  0.63                     -  \n",
            "3   1595     1129   1619  0.82                     -  \n",
            "4    957      853   1051  0.51                     -  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "VOG Binary Matrix:\n",
            "(3936, 4728)\n",
            "          VOG00025  VOG00035  VOG00038  VOG00048  VOG00056  VOG00068  \\\n",
            "sequence                                                               \n",
            "seq1             0         0         0         0         0         0   \n",
            "seq2             0         0         0         0         0         0   \n",
            "seq3             0         0         0         0         0         0   \n",
            "seq4             0         0         0         0         0         0   \n",
            "seq5             0         0         0         0         0         0   \n",
            "\n",
            "          VOG00079  VOG00148  VOG00155  VOG00189  ...  VOG73339  VOG73341  \\\n",
            "sequence                                          ...                       \n",
            "seq1             0         0         0         0  ...         0         0   \n",
            "seq2             0         0         0         0  ...         0         0   \n",
            "seq3             0         0         0         0  ...         0         0   \n",
            "seq4             0         0         0         0  ...         0         0   \n",
            "seq5             0         0         0         0  ...         0         0   \n",
            "\n",
            "          VOG73342  VOG73343  VOG73346  VOG73353  VOG73360  VOG73363  \\\n",
            "sequence                                                               \n",
            "seq1             0         0         0         0         0         0   \n",
            "seq2             0         0         0         0         0         0   \n",
            "seq3             0         0         0         0         0         0   \n",
            "seq4             0         0         0         0         0         0   \n",
            "seq5             0         0         0         0         0         0   \n",
            "\n",
            "          VOG73366  VOG73372  \n",
            "sequence                      \n",
            "seq1             0         0  \n",
            "seq2             0         0  \n",
            "seq3             0         1  \n",
            "seq4             0         0  \n",
            "seq5             0         0  \n",
            "\n",
            "[5 rows x 4728 columns]\n",
            "\n",
            "VFAM Binary Matrix:\n",
            "(3936, 2675)\n",
            "          VFAM00004  VFAM00007  VFAM00022  VFAM00029  VFAM00031  VFAM00032  \\\n",
            "sequence                                                                     \n",
            "seq1              0          0          0          0          0          0   \n",
            "seq2              0          0          0          0          0          0   \n",
            "seq3              0          1          0          0          0          0   \n",
            "seq4              0          1          0          0          0          0   \n",
            "seq5              0          0          0          0          0          0   \n",
            "\n",
            "          VFAM00034  VFAM00036  VFAM00047  VFAM00050  ...  VFAM41285  \\\n",
            "sequence                                              ...              \n",
            "seq1              0          0          0          0  ...          0   \n",
            "seq2              0          0          0          0  ...          0   \n",
            "seq3              0          0          0          0  ...          0   \n",
            "seq4              0          0          0          0  ...          0   \n",
            "seq5              0          0          0          0  ...          0   \n",
            "\n",
            "          VFAM41286  VFAM41291  VFAM41293  VFAM41297  VFAM41298  VFAM41299  \\\n",
            "sequence                                                                     \n",
            "seq1              0          0          0          0          0          0   \n",
            "seq2              0          0          0          0          0          0   \n",
            "seq3              0          0          0          0          0          0   \n",
            "seq4              0          0          0          0          0          0   \n",
            "seq5              0          0          0          0          0          0   \n",
            "\n",
            "          VFAM41302  VFAM41303  VFAM41307  \n",
            "sequence                                   \n",
            "seq1              0          0          0  \n",
            "seq2              0          0          0  \n",
            "seq3              0          0          0  \n",
            "seq4              0          0          0  \n",
            "seq5              0          0          0  \n",
            "\n",
            "[5 rows x 2675 columns]\n",
            "\n",
            "PHMMs Binary Matrix:\n",
            "(3936, 7403)\n",
            "          VOG00025  VOG00035  VOG00038  VOG00048  VOG00056  VOG00068  \\\n",
            "sequence                                                               \n",
            "seq1             0         0         0         0         0         0   \n",
            "seq2             0         0         0         0         0         0   \n",
            "seq3             0         0         0         0         0         0   \n",
            "seq4             0         0         0         0         0         0   \n",
            "seq5             0         0         0         0         0         0   \n",
            "\n",
            "          VOG00079  VOG00148  VOG00155  VOG00189  ...  VFAM41285  VFAM41286  \\\n",
            "sequence                                          ...                         \n",
            "seq1             0         0         0         0  ...          0          0   \n",
            "seq2             0         0         0         0  ...          0          0   \n",
            "seq3             0         0         0         0  ...          0          0   \n",
            "seq4             0         0         0         0  ...          0          0   \n",
            "seq5             0         0         0         0  ...          0          0   \n",
            "\n",
            "          VFAM41291  VFAM41293  VFAM41297  VFAM41298  VFAM41299  VFAM41302  \\\n",
            "sequence                                                                     \n",
            "seq1              0          0          0          0          0          0   \n",
            "seq2              0          0          0          0          0          0   \n",
            "seq3              0          0          0          0          0          0   \n",
            "seq4              0          0          0          0          0          0   \n",
            "seq5              0          0          0          0          0          0   \n",
            "\n",
            "          VFAM41303  VFAM41307  \n",
            "sequence                        \n",
            "seq1              0          0  \n",
            "seq2              0          0  \n",
            "seq3              0          0  \n",
            "seq4              0          0  \n",
            "seq5              0          0  \n",
            "\n",
            "[5 rows x 7403 columns]\n"
          ]
        }
      ],
      "source": [
        "# display vog and vfam dfs\n",
        "print(\"VOG table:\")\n",
        "print(vog_table.shape)\n",
        "print(vog_table.head())\n",
        "\n",
        "# print(\"\\nVFAM table:\")\n",
        "print(vfam_table.shape)\n",
        "print(vfam_table.head())\n",
        "\n",
        "\n",
        "# display binary matrices\n",
        "print(\"\\nVOG Binary Matrix:\")\n",
        "print(vog_binary_matrix.shape)\n",
        "print(vog_binary_matrix.head())\n",
        "\n",
        "print(\"\\nVFAM Binary Matrix:\")\n",
        "print(vfam_binary_matrix.shape)\n",
        "print(vfam_binary_matrix.head())\n",
        "\n",
        "print(\"\\nPHMMs Binary Matrix:\")\n",
        "print(allphmms_binary_matrix.shape)\n",
        "print(allphmms_binary_matrix.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954d9c2e-3cca-477d-b97f-319af0379882",
      "metadata": {
        "id": "954d9c2e-3cca-477d-b97f-319af0379882"
      },
      "source": [
        "## Train, test and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a59474f-85db-4b0f-bb96-0737c17c9144",
      "metadata": {
        "id": "7a59474f-85db-4b0f-bb96-0737c17c9144"
      },
      "outputs": [],
      "source": [
        "y = pd.read_csv('/Users/lizsteny/Documents/Academia/MSc Bioinformatics/Project/bif_project/data/y.csv', na_values=['?'])\n",
        "y.set_index('sequence', inplace=True)\n",
        "\n",
        "# define paths\n",
        "input_path = \"/Users/lizsteny/Documents/Academia/MSc Bioinformatics/Project/bif_project/features/pro_features\"\n",
        "results_dir = \"/Users/lizsteny/Documents/Academia/MSc Bioinformatics/Project/bif_project/results/pro_results\"\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733a658d-2f50-40b5-b6c7-b631bfbbf38c",
      "metadata": {
        "id": "733a658d-2f50-40b5-b6c7-b631bfbbf38c"
      },
      "outputs": [],
      "source": [
        "# main loop to process each descriptor file\n",
        "descriptors = [\n",
        "\"vog_table\", \"vfam_table\", \"allphmms_table\"\n",
        "]\n",
        "\n",
        "for descriptor in descriptors:\n",
        "    # load data\n",
        "    x = load_data(descriptor)\n",
        "\n",
        "    # plot top features distribution\n",
        "    plot_top_features(x, descriptor)\n",
        "\n",
        "    # save descriptive statistics\n",
        "    save_statistics(x, descriptor)\n",
        "\n",
        "    # calculate and save correlation\n",
        "    correlation_with_target = calculate_and_plot_correlation(x, y['infection'], descriptor)\n",
        "\n",
        "    # select features based on correlation threshold\n",
        "    x_selected = select_features_by_correlation(x, correlation_with_target)\n",
        "    y_selected = y['infection']\n",
        "\n",
        "    # plot pairplot\n",
        "    # plot_pairplot(x_selected, y_selected, descriptor)\n",
        "\n",
        "    # train-test split\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_selected, y_selected, test_size=0.2, random_state=42)\n",
        "\n",
        "    # train model and evaluate\n",
        "    model = train_and_evaluate_model(x_train, x_test, y_train, y_test, descriptor)\n",
        "\n",
        "    # cross-validation\n",
        "    cross_validate_model(model, x_selected, y_selected, descriptor)\n",
        "\n",
        "    # plot feature importances\n",
        "    plot_feature_importance(model, x_selected, descriptor)\n",
        "\n",
        "    print(f\"Processed and saved results for {descriptor}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "# loop through each descriptor and extract evaluation and CV scores\n",
        "for descriptor in descriptors:\n",
        "    # define file paths for evaluation and CV scores\n",
        "    evaluation_file = os.path.join(results_dir, f\"{descriptor}_evaluation.txt\")\n",
        "    cv_scores_file = os.path.join(results_dir, f\"{descriptor}_cv_scores.txt\")\n",
        "\n",
        "    # initialize variables to store scores\n",
        "    accuracy = None\n",
        "    classification_report = None\n",
        "    cv_scores = []\n",
        "    mean_cv_score = None\n",
        "\n",
        "    # read and parse the evaluation file if it exists\n",
        "    if os.path.exists(evaluation_file):\n",
        "        with open(evaluation_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                if line.startswith(\"Accuracy:\"):\n",
        "                    accuracy = float(line.split(\":\")[1].strip())\n",
        "                elif line.startswith(\"Classification Report:\"):\n",
        "                    classification_report = \"\".join(lines[lines.index(line)+1:]).strip()  # collect the full classification report\n",
        "    else:\n",
        "        print(f\"Warning: Evaluation file for {descriptor} not found.\")\n",
        "\n",
        "    # read and parse the CV scores file if it exists\n",
        "    if os.path.exists(cv_scores_file):\n",
        "        with open(cv_scores_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            # extract CV scores and mean CV score\n",
        "            cv_scores = [float(score) for score in re.findall(r\"\\d+\\.\\d+\", lines[1])]  # assuming scores are on the second line\n",
        "            mean_cv_score = float(re.search(r\"Mean Cross-Validation Score: (\\d+\\.\\d+)\", lines[-1]).group(1))\n",
        "    else:\n",
        "        print(f\"Warning: CV scores file for {descriptor} not found.\")\n",
        "\n",
        "    # add a row to the data list\n",
        "    data.append({\n",
        "        \"Method\": descriptor,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Mean CV Score\": mean_cv_score,\n",
        "        \"CV Scores\": cv_scores,\n",
        "        \"Classification Report\": classification_report\n",
        "    })\n",
        "\n",
        "# create a df from the collected data\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# save the df to a CSV file\n",
        "df.to_csv(os.path.join(results_dir, \"summary/combined_evaluation_cv_scores.csv\"), index=False)\n",
        "print(\"Combined evaluation and CV scores saved to combined_evaluation_cv_scores.csv\")"
      ],
      "metadata": {
        "id": "_Lj9DziHwypA"
      },
      "id": "_Lj9DziHwypA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}